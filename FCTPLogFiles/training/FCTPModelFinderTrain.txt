INFO 06/19/2022 08:36:58 PM TRAINING: Search for best model started
INFO 06/19/2022 08:36:58 PM TRAINING: Search for best logistic regressor model started
INFO 06/19/2022 08:36:58 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'penalty', 'solver']))  of Logistic Regressor
INFO 06/19/2022 08:37:55 PM TRAINING: The optimum parameters of Logistic Regressor are C=3, penalty=l1,solver=saga  with the accuracy score of 0.7307647976133975
INFO 06/19/2022 08:37:55 PM TRAINING: Best Logistic  Regressor trained
INFO 06/19/2022 08:37:55 PM TRAINING: Search for best logistic regressor model ended
INFO 06/19/2022 08:37:55 PM TRAINING: Search for best svc model started
INFO 06/19/2022 08:37:55 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'kernel', 'degree', 'gamma'])) of SVC
INFO 06/19/2022 08:38:16 PM TRAINING: The optimum parameters of SVC are kernel=rbf, gamma=auto, C=10, degree =2 with the accuracy score of 0.742406264831514
INFO 06/19/2022 08:38:17 PM TRAINING: Best SVC trained
INFO 06/19/2022 08:38:17 PM TRAINING: Search for best svc model ended
INFO 06/19/2022 08:38:17 PM TRAINING: Search for best random forest classifier model started
INFO 06/19/2022 08:38:17 PM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['n_estimators', 'criterion', 'min_samples_split', 'max_features', 'ccp_alpha'])) of random forest classifier 
INFO 06/19/2022 08:51:33 PM TRAINING: The optimum parameters of random forrest classifier are n_estimators=130, criterion=entropy, min_samples_split=3, max_features =auto, ccp_alpha=0.003 with the accuracy of 0.7552478134110787
INFO 06/19/2022 08:51:33 PM TRAINING: Best random forest classifier trained
INFO 06/19/2022 08:51:34 PM TRAINING: Search for best random forest classifier model ended
INFO 06/19/2022 08:51:34 PM TRAINING: Search for best xgb classifier model started
INFO 06/19/2022 08:51:34 PM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['learning_rate', 'colsample_bytree', 'max_depth', 'n_estimators', 'verbosity'])) of xgb classifier
INFO 06/19/2022 09:24:20 PM TRAINING: The optimum parameters of xgb-classifier are learning_rate=0.01, max_depth=10, colsample_bytree=0.4, n_estimators =1000 with the accuracy score of 0.762221167536782
INFO 06/19/2022 09:24:34 PM TRAINING: Best xgb classifier trained
INFO 06/19/2022 09:24:34 PM TRAINING: Search for best xgb classifier model ended
INFO 06/19/2022 09:24:34 PM TRAINING: The best model is xgb classifier with accuracy of 0.7835951134380453for 573 instances
INFO 06/19/2022 09:24:34 PM TRAINING: Search for best model started
INFO 06/19/2022 09:24:34 PM TRAINING: Search for best logistic regressor model started
INFO 06/19/2022 09:24:34 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'penalty', 'solver']))  of Logistic Regressor
INFO 06/19/2022 09:24:52 PM TRAINING: The optimum parameters of Logistic Regressor are C=10, penalty=l1,solver=saga  with the accuracy score of 0.8600067957866123
INFO 06/19/2022 09:24:52 PM TRAINING: Best Logistic  Regressor trained
INFO 06/19/2022 09:24:52 PM TRAINING: Search for best logistic regressor model ended
INFO 06/19/2022 09:24:52 PM TRAINING: Search for best svc model started
INFO 06/19/2022 09:24:52 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'kernel', 'degree', 'gamma'])) of SVC
INFO 06/19/2022 09:24:55 PM TRAINING: The optimum parameters of SVC are kernel=poly, gamma=auto, C=10, degree =5 with the accuracy score of 0.8691811077132179
INFO 06/19/2022 09:24:55 PM TRAINING: Best SVC trained
INFO 06/19/2022 09:24:55 PM TRAINING: Search for best svc model ended
INFO 06/19/2022 09:24:55 PM TRAINING: Search for best random forest classifier model started
INFO 06/19/2022 09:24:55 PM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['n_estimators', 'criterion', 'min_samples_split', 'max_features', 'ccp_alpha'])) of random forest classifier 
INFO 06/19/2022 09:30:56 PM TRAINING: The optimum parameters of random forrest classifier are n_estimators=100, criterion=entropy, min_samples_split=4, max_features =sqrt, ccp_alpha=0.009000000000000001 with the accuracy of 0.8802242609582059
INFO 06/19/2022 09:30:57 PM TRAINING: Best random forest classifier trained
INFO 06/19/2022 09:30:57 PM TRAINING: Search for best random forest classifier model ended
INFO 06/19/2022 09:30:57 PM TRAINING: Search for best xgb classifier model started
INFO 06/19/2022 09:30:57 PM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['learning_rate', 'colsample_bytree', 'max_depth', 'n_estimators', 'verbosity'])) of xgb classifier
INFO 06/19/2022 09:42:17 PM TRAINING: The optimum parameters of xgb-classifier are learning_rate=0.3, max_depth=15, colsample_bytree=0.7, n_estimators =3000 with the accuracy score of 0.8857798165137615
INFO 06/19/2022 09:42:23 PM TRAINING: Best xgb classifier trained
INFO 06/19/2022 09:42:23 PM TRAINING: Search for best xgb classifier model ended
INFO 06/19/2022 09:42:23 PM TRAINING: The best model is svc with accuracy of 0.8516483516483516for 182 instances
INFO 06/19/2022 09:42:23 PM TRAINING: Search for best model started
INFO 06/19/2022 09:42:23 PM TRAINING: Search for best logistic regressor model started
INFO 06/19/2022 09:42:23 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'penalty', 'solver']))  of Logistic Regressor
INFO 06/19/2022 09:42:36 PM TRAINING: The optimum parameters of Logistic Regressor are C=10, penalty=l1,solver=saga  with the accuracy score of 0.6611336032388664
INFO 06/19/2022 09:42:36 PM TRAINING: Best Logistic  Regressor trained
INFO 06/19/2022 09:42:36 PM TRAINING: Search for best logistic regressor model ended
INFO 06/19/2022 09:42:36 PM TRAINING: Search for best svc model started
INFO 06/19/2022 09:42:36 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'kernel', 'degree', 'gamma'])) of SVC
INFO 06/19/2022 09:42:37 PM TRAINING: The optimum parameters of SVC are kernel=poly, gamma=auto, C=10, degree =5 with the accuracy score of 0.7076923076923077
INFO 06/19/2022 09:42:37 PM TRAINING: Best SVC trained
INFO 06/19/2022 09:42:37 PM TRAINING: Search for best svc model ended
INFO 06/19/2022 09:42:37 PM TRAINING: Search for best random forest classifier model started
INFO 06/19/2022 09:42:37 PM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['n_estimators', 'criterion', 'min_samples_split', 'max_features', 'ccp_alpha'])) of random forest classifier 
INFO 06/19/2022 09:47:21 PM TRAINING: The optimum parameters of random forrest classifier are n_estimators=130, criterion=entropy, min_samples_split=2, max_features =sqrt, ccp_alpha=0.007 with the accuracy of 0.6812415654520917
INFO 06/19/2022 09:47:21 PM TRAINING: Best random forest classifier trained
INFO 06/19/2022 09:47:21 PM TRAINING: Search for best random forest classifier model ended
INFO 06/19/2022 09:47:21 PM TRAINING: Search for best xgb classifier model started
INFO 06/19/2022 09:47:21 PM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['learning_rate', 'colsample_bytree', 'max_depth', 'n_estimators', 'verbosity'])) of xgb classifier
INFO 06/19/2022 09:56:52 PM TRAINING: The optimum parameters of xgb-classifier are learning_rate=1, max_depth=15, colsample_bytree=0.7, n_estimators =3000 with the accuracy score of 0.682051282051282
INFO 06/19/2022 09:56:59 PM TRAINING: Best xgb classifier trained
INFO 06/19/2022 09:56:59 PM TRAINING: Search for best xgb classifier model ended
INFO 06/19/2022 09:56:59 PM TRAINING: The best model is xgb classifier with accuracy of 0.7692307692307693for 65 instances
INFO 06/19/2022 09:56:59 PM TRAINING: Search for best model started
INFO 06/19/2022 09:56:59 PM TRAINING: Search for best logistic regressor model started
INFO 06/19/2022 09:56:59 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'penalty', 'solver']))  of Logistic Regressor
INFO 06/19/2022 09:57:23 PM TRAINING: The optimum parameters of Logistic Regressor are C=10, penalty=l1,solver=saga  with the accuracy score of 0.6736997360658282
INFO 06/19/2022 09:57:23 PM TRAINING: Best Logistic  Regressor trained
INFO 06/19/2022 09:57:23 PM TRAINING: Search for best logistic regressor model ended
INFO 06/19/2022 09:57:23 PM TRAINING: Search for best svc model started
INFO 06/19/2022 09:57:23 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'kernel', 'degree', 'gamma'])) of SVC
INFO 06/19/2022 09:57:28 PM TRAINING: The optimum parameters of SVC are kernel=poly, gamma=auto, C=10, degree =5 with the accuracy score of 0.7018785902810122
INFO 06/19/2022 09:57:28 PM TRAINING: Best SVC trained
INFO 06/19/2022 09:57:28 PM TRAINING: Search for best svc model ended
INFO 06/19/2022 09:57:28 PM TRAINING: Search for best random forest classifier model started
INFO 06/19/2022 09:57:28 PM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['n_estimators', 'criterion', 'min_samples_split', 'max_features', 'ccp_alpha'])) of random forest classifier 
INFO 06/19/2022 10:04:01 PM TRAINING: The optimum parameters of random forrest classifier are n_estimators=130, criterion=entropy, min_samples_split=3, max_features =sqrt, ccp_alpha=0.0 with the accuracy of 0.7301505977332712
INFO 06/19/2022 10:04:01 PM TRAINING: Best random forest classifier trained
INFO 06/19/2022 10:04:01 PM TRAINING: Search for best random forest classifier model ended
INFO 06/19/2022 10:04:01 PM TRAINING: Search for best xgb classifier model started
INFO 06/19/2022 10:04:01 PM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['learning_rate', 'colsample_bytree', 'max_depth', 'n_estimators', 'verbosity'])) of xgb classifier
INFO 06/19/2022 10:16:58 PM TRAINING: The optimum parameters of xgb-classifier are learning_rate=0.03, max_depth=15, colsample_bytree=0.6, n_estimators =1000 with the accuracy score of 0.7495109455053564
INFO 06/19/2022 10:17:03 PM TRAINING: Best xgb classifier trained
INFO 06/19/2022 10:17:03 PM TRAINING: Search for best xgb classifier model ended
INFO 06/19/2022 10:17:03 PM TRAINING: The best model is svc with accuracy of 0.7789473684210526for 190 instances
INFO 06/19/2022 10:17:03 PM TRAINING: Search for best model started
INFO 06/19/2022 10:17:03 PM TRAINING: Search for best logistic regressor model started
INFO 06/19/2022 10:17:03 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'penalty', 'solver']))  of Logistic Regressor
INFO 06/19/2022 10:17:12 PM TRAINING: The optimum parameters of Logistic Regressor are C=0.3, penalty=l2,solver=newton-cg  with the accuracy score of 0.9331628303495311
INFO 06/19/2022 10:17:12 PM TRAINING: Best Logistic  Regressor trained
INFO 06/19/2022 10:17:12 PM TRAINING: Search for best logistic regressor model ended
INFO 06/19/2022 10:17:12 PM TRAINING: Search for best svc model started
INFO 06/19/2022 10:17:12 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'kernel', 'degree', 'gamma'])) of SVC
INFO 06/19/2022 10:17:14 PM TRAINING: The optimum parameters of SVC are kernel=linear, gamma=scale, C=1, degree =2 with the accuracy score of 0.9418584825234442
INFO 06/19/2022 10:17:14 PM TRAINING: Best SVC trained
INFO 06/19/2022 10:17:14 PM TRAINING: Search for best svc model ended
INFO 06/19/2022 10:17:14 PM TRAINING: Search for best random forest classifier model started
INFO 06/19/2022 10:17:14 PM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['n_estimators', 'criterion', 'min_samples_split', 'max_features', 'ccp_alpha'])) of random forest classifier 
INFO 06/19/2022 10:21:50 PM TRAINING: The optimum parameters of random forrest classifier are n_estimators=130, criterion=gini, min_samples_split=2, max_features =auto, ccp_alpha=0.003 with the accuracy of 0.9302216538789428
INFO 06/19/2022 10:21:50 PM TRAINING: Best random forest classifier trained
INFO 06/19/2022 10:21:50 PM TRAINING: Search for best random forest classifier model ended
INFO 06/19/2022 10:21:50 PM TRAINING: Search for best xgb classifier model started
INFO 06/19/2022 10:21:50 PM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['learning_rate', 'colsample_bytree', 'max_depth', 'n_estimators', 'verbosity'])) of xgb classifier
INFO 06/19/2022 10:31:04 PM TRAINING: The optimum parameters of xgb-classifier are learning_rate=1, max_depth=20, colsample_bytree=0.4, n_estimators =1000 with the accuracy score of 0.9418158567774937
INFO 06/19/2022 10:31:05 PM TRAINING: Best xgb classifier trained
INFO 06/19/2022 10:31:05 PM TRAINING: Search for best xgb classifier model ended
INFO 06/19/2022 10:31:05 PM TRAINING: The best model is svc with accuracy of 0.9391304347826087for 115 instances
INFO 06/19/2022 10:31:05 PM TRAINING: Search for best model started
INFO 06/19/2022 10:31:05 PM TRAINING: Search for best logistic regressor model started
INFO 06/19/2022 10:31:05 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'penalty', 'solver']))  of Logistic Regressor
INFO 06/19/2022 10:31:27 PM TRAINING: The optimum parameters of Logistic Regressor are C=10, penalty=l1,solver=saga  with the accuracy score of 0.9126159554730984
INFO 06/19/2022 10:31:27 PM TRAINING: Best Logistic  Regressor trained
INFO 06/19/2022 10:31:27 PM TRAINING: Search for best logistic regressor model ended
INFO 06/19/2022 10:31:27 PM TRAINING: Search for best svc model started
INFO 06/19/2022 10:31:27 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'kernel', 'degree', 'gamma'])) of SVC
INFO 06/19/2022 10:31:30 PM TRAINING: The optimum parameters of SVC are kernel=linear, gamma=scale, C=10, degree =2 with the accuracy score of 0.9106163677592249
INFO 06/19/2022 10:31:30 PM TRAINING: Best SVC trained
INFO 06/19/2022 10:31:30 PM TRAINING: Search for best svc model ended
INFO 06/19/2022 10:31:30 PM TRAINING: Search for best random forest classifier model started
INFO 06/19/2022 10:31:30 PM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['n_estimators', 'criterion', 'min_samples_split', 'max_features', 'ccp_alpha'])) of random forest classifier 
INFO 06/19/2022 10:36:47 PM TRAINING: The optimum parameters of random forrest classifier are n_estimators=130, criterion=gini, min_samples_split=3, max_features =log2, ccp_alpha=0.002 with the accuracy of 0.9247990105132964
INFO 06/19/2022 10:36:47 PM TRAINING: Best random forest classifier trained
INFO 06/19/2022 10:36:47 PM TRAINING: Search for best random forest classifier model ended
INFO 06/19/2022 10:36:47 PM TRAINING: Search for best xgb classifier model started
INFO 06/19/2022 10:36:47 PM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['learning_rate', 'colsample_bytree', 'max_depth', 'n_estimators', 'verbosity'])) of xgb classifier
INFO 06/19/2022 10:47:02 PM TRAINING: The optimum parameters of xgb-classifier are learning_rate=1, max_depth=10, colsample_bytree=0.3, n_estimators =300 with the accuracy score of 0.9288806431663575
INFO 06/19/2022 10:47:03 PM TRAINING: Best xgb classifier trained
INFO 06/19/2022 10:47:03 PM TRAINING: Search for best xgb classifier model ended
INFO 06/19/2022 10:47:03 PM TRAINING: The best model is xgb classifier with accuracy of 0.9454545454545454for 165 instances
INFO 06/19/2022 10:47:03 PM TRAINING: Search for best model started
INFO 06/19/2022 10:47:03 PM TRAINING: Search for best logistic regressor model started
INFO 06/19/2022 10:47:03 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'penalty', 'solver']))  of Logistic Regressor
INFO 06/19/2022 10:47:18 PM TRAINING: The optimum parameters of Logistic Regressor are C=1, penalty=l2,solver=newton-cg  with the accuracy score of 0.8956630525437866
INFO 06/19/2022 10:47:18 PM TRAINING: Best Logistic  Regressor trained
INFO 06/19/2022 10:47:18 PM TRAINING: Search for best logistic regressor model ended
INFO 06/19/2022 10:47:18 PM TRAINING: Search for best svc model started
INFO 06/19/2022 10:47:18 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'kernel', 'degree', 'gamma'])) of SVC
INFO 06/19/2022 10:47:21 PM TRAINING: The optimum parameters of SVC are kernel=rbf, gamma=auto, C=10, degree =2 with the accuracy score of 0.9395996663886572
INFO 06/19/2022 10:47:21 PM TRAINING: Best SVC trained
INFO 06/19/2022 10:47:21 PM TRAINING: Search for best svc model ended
INFO 06/19/2022 10:47:21 PM TRAINING: Search for best random forest classifier model started
INFO 06/19/2022 10:47:21 PM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['n_estimators', 'criterion', 'min_samples_split', 'max_features', 'ccp_alpha'])) of random forest classifier 
INFO 06/19/2022 10:53:03 PM TRAINING: The optimum parameters of random forrest classifier are n_estimators=100, criterion=gini, min_samples_split=5, max_features =sqrt, ccp_alpha=0.001 with the accuracy of 0.9322935779816515
INFO 06/19/2022 10:53:04 PM TRAINING: Best random forest classifier trained
INFO 06/19/2022 10:53:04 PM TRAINING: Search for best random forest classifier model ended
INFO 06/19/2022 10:53:04 PM TRAINING: Search for best xgb classifier model started
INFO 06/19/2022 10:53:04 PM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['learning_rate', 'colsample_bytree', 'max_depth', 'n_estimators', 'verbosity'])) of xgb classifier
INFO 06/19/2022 11:03:29 PM TRAINING: The optimum parameters of xgb-classifier are learning_rate=1, max_depth=20, colsample_bytree=0.7, n_estimators =300 with the accuracy score of 0.9303586321934947
INFO 06/19/2022 11:03:30 PM TRAINING: Best xgb classifier trained
INFO 06/19/2022 11:03:30 PM TRAINING: Search for best xgb classifier model ended
INFO 06/19/2022 11:03:30 PM TRAINING: The best model is svc with accuracy of 0.9230769230769231for 182 instances
INFO 06/19/2022 11:03:30 PM TRAINING: Search for best model started
INFO 06/19/2022 11:03:30 PM TRAINING: Search for best logistic regressor model started
INFO 06/19/2022 11:03:30 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'penalty', 'solver']))  of Logistic Regressor
INFO 06/19/2022 11:03:47 PM TRAINING: The optimum parameters of Logistic Regressor are C=3, penalty=l2,solver=newton-cg  with the accuracy score of 0.6775128564749884
INFO 06/19/2022 11:03:47 PM TRAINING: Best Logistic  Regressor trained
INFO 06/19/2022 11:03:47 PM TRAINING: Search for best logistic regressor model ended
INFO 06/19/2022 11:03:47 PM TRAINING: Search for best svc model started
INFO 06/19/2022 11:03:47 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'kernel', 'degree', 'gamma'])) of SVC
INFO 06/19/2022 11:03:50 PM TRAINING: The optimum parameters of SVC are kernel=rbf, gamma=auto, C=10, degree =2 with the accuracy score of 0.7014258999532492
INFO 06/19/2022 11:03:50 PM TRAINING: Best SVC trained
INFO 06/19/2022 11:03:50 PM TRAINING: Search for best svc model ended
INFO 06/19/2022 11:03:50 PM TRAINING: Search for best random forest classifier model started
INFO 06/19/2022 11:03:50 PM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['n_estimators', 'criterion', 'min_samples_split', 'max_features', 'ccp_alpha'])) of random forest classifier 
INFO 06/19/2022 11:16:51 PM TRAINING: The optimum parameters of random forrest classifier are n_estimators=150, criterion=entropy, min_samples_split=2, max_features =sqrt, ccp_alpha=0.005 with the accuracy of 0.7382889200561009
INFO 06/19/2022 11:16:52 PM TRAINING: Best random forest classifier trained
INFO 06/19/2022 11:16:52 PM TRAINING: Search for best random forest classifier model ended
INFO 06/19/2022 11:16:52 PM TRAINING: Search for best xgb classifier model started
INFO 06/19/2022 11:16:52 PM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['learning_rate', 'colsample_bytree', 'max_depth', 'n_estimators', 'verbosity'])) of xgb classifier
INFO 06/19/2022 11:28:59 PM TRAINING: The optimum parameters of xgb-classifier are learning_rate=0.03, max_depth=10, colsample_bytree=0.6, n_estimators =300 with the accuracy score of 0.7294296400187004
INFO 06/19/2022 11:29:01 PM TRAINING: Best xgb classifier trained
INFO 06/19/2022 11:29:01 PM TRAINING: Search for best xgb classifier model ended
INFO 06/19/2022 11:29:01 PM TRAINING: The best model is random forest classifier with accuracy of 0.7987012987012987for 154 instances
INFO 06/19/2022 11:29:01 PM TRAINING: Search for best model started
INFO 06/19/2022 11:29:01 PM TRAINING: Search for best logistic regressor model started
INFO 06/19/2022 11:29:01 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'penalty', 'solver']))  of Logistic Regressor
INFO 06/19/2022 11:29:14 PM TRAINING: The optimum parameters of Logistic Regressor are C=10, penalty=l1,solver=saga  with the accuracy score of 0.7754285714285715
INFO 06/19/2022 11:29:14 PM TRAINING: Best Logistic  Regressor trained
INFO 06/19/2022 11:29:14 PM TRAINING: Search for best logistic regressor model ended
INFO 06/19/2022 11:29:14 PM TRAINING: Search for best svc model started
INFO 06/19/2022 11:29:14 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'kernel', 'degree', 'gamma'])) of SVC
INFO 06/19/2022 11:29:16 PM TRAINING: The optimum parameters of SVC are kernel=poly, gamma=auto, C=10, degree =3 with the accuracy score of 0.7952653061224491
INFO 06/19/2022 11:29:16 PM TRAINING: Best SVC trained
INFO 06/19/2022 11:29:16 PM TRAINING: Search for best svc model ended
INFO 06/19/2022 11:29:16 PM TRAINING: Search for best random forest classifier model started
INFO 06/19/2022 11:29:16 PM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['n_estimators', 'criterion', 'min_samples_split', 'max_features', 'ccp_alpha'])) of random forest classifier 
INFO 06/19/2022 11:34:11 PM TRAINING: The optimum parameters of random forrest classifier are n_estimators=150, criterion=gini, min_samples_split=2, max_features =sqrt, ccp_alpha=0.003 with the accuracy of 0.7909387755102041
INFO 06/19/2022 11:34:11 PM TRAINING: Best random forest classifier trained
INFO 06/19/2022 11:34:11 PM TRAINING: Search for best random forest classifier model ended
INFO 06/19/2022 11:34:11 PM TRAINING: Search for best xgb classifier model started
INFO 06/19/2022 11:34:11 PM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['learning_rate', 'colsample_bytree', 'max_depth', 'n_estimators', 'verbosity'])) of xgb classifier
INFO 06/19/2022 11:43:32 PM TRAINING: The optimum parameters of xgb-classifier are learning_rate=0.3, max_depth=15, colsample_bytree=0.4, n_estimators =3000 with the accuracy score of 0.7671836734693878
INFO 06/19/2022 11:43:38 PM TRAINING: Best xgb classifier trained
INFO 06/19/2022 11:43:38 PM TRAINING: Search for best xgb classifier model ended
INFO 06/19/2022 11:43:38 PM TRAINING: The best model is svc with accuracy of 0.7349397590361446for 83 instances
INFO 06/19/2022 11:43:38 PM TRAINING: Search for best model started
INFO 06/19/2022 11:43:38 PM TRAINING: Search for best logistic regressor model started
INFO 06/19/2022 11:43:38 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'penalty', 'solver']))  of Logistic Regressor
INFO 06/19/2022 11:44:01 PM TRAINING: The optimum parameters of Logistic Regressor are C=10, penalty=l1,solver=saga  with the accuracy score of 0.6247759522031366
INFO 06/19/2022 11:44:01 PM TRAINING: Best Logistic  Regressor trained
INFO 06/19/2022 11:44:01 PM TRAINING: Search for best logistic regressor model ended
INFO 06/19/2022 11:44:01 PM TRAINING: Search for best svc model started
INFO 06/19/2022 11:44:01 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'kernel', 'degree', 'gamma'])) of SVC
INFO 06/19/2022 11:44:05 PM TRAINING: The optimum parameters of SVC are kernel=poly, gamma=auto, C=10, degree =5 with the accuracy score of 0.6751120238984317
INFO 06/19/2022 11:44:05 PM TRAINING: Best SVC trained
INFO 06/19/2022 11:44:05 PM TRAINING: Search for best svc model ended
INFO 06/19/2022 11:44:05 PM TRAINING: Search for best random forest classifier model started
INFO 06/19/2022 11:44:05 PM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['n_estimators', 'criterion', 'min_samples_split', 'max_features', 'ccp_alpha'])) of random forest classifier 
INFO 06/19/2022 11:50:35 PM TRAINING: The optimum parameters of random forrest classifier are n_estimators=100, criterion=entropy, min_samples_split=4, max_features =auto, ccp_alpha=0.006 with the accuracy of 0.6846713965646004
INFO 06/19/2022 11:50:35 PM TRAINING: Best random forest classifier trained
INFO 06/19/2022 11:50:35 PM TRAINING: Search for best random forest classifier model ended
INFO 06/19/2022 11:50:35 PM TRAINING: Search for best xgb classifier model started
INFO 06/19/2022 11:50:35 PM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['learning_rate', 'colsample_bytree', 'max_depth', 'n_estimators', 'verbosity'])) of xgb classifier
INFO 06/20/2022 12:04:56 AM TRAINING: The optimum parameters of xgb-classifier are learning_rate=1, max_depth=10, colsample_bytree=0.6, n_estimators =300 with the accuracy score of 0.6846713965646005
INFO 06/20/2022 12:04:56 AM TRAINING: Best xgb classifier trained
INFO 06/20/2022 12:04:56 AM TRAINING: Search for best xgb classifier model ended
INFO 06/20/2022 12:04:56 AM TRAINING: The best model is random forest classifier with accuracy of 0.7398843930635838for 173 instances
INFO 06/20/2022 12:04:57 AM TRAINING: Search for best model started
INFO 06/20/2022 12:04:57 AM TRAINING: Search for best logistic regressor model started
INFO 06/20/2022 12:04:57 AM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'penalty', 'solver']))  of Logistic Regressor
INFO 06/20/2022 12:05:12 AM TRAINING: The optimum parameters of Logistic Regressor are C=10, penalty=l1,solver=saga  with the accuracy score of 0.6708196721311477
INFO 06/20/2022 12:05:12 AM TRAINING: Best Logistic  Regressor trained
INFO 06/20/2022 12:05:12 AM TRAINING: Search for best logistic regressor model ended
INFO 06/20/2022 12:05:12 AM TRAINING: Search for best svc model started
INFO 06/20/2022 12:05:12 AM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'kernel', 'degree', 'gamma'])) of SVC
INFO 06/20/2022 12:05:14 AM TRAINING: The optimum parameters of SVC are kernel=poly, gamma=auto, C=10, degree =5 with the accuracy score of 0.7302185792349727
INFO 06/20/2022 12:05:14 AM TRAINING: Best SVC trained
INFO 06/20/2022 12:05:14 AM TRAINING: Search for best svc model ended
INFO 06/20/2022 12:05:14 AM TRAINING: Search for best random forest classifier model started
INFO 06/20/2022 12:05:14 AM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['n_estimators', 'criterion', 'min_samples_split', 'max_features', 'ccp_alpha'])) of random forest classifier 
INFO 06/20/2022 12:10:21 AM TRAINING: The optimum parameters of random forrest classifier are n_estimators=130, criterion=entropy, min_samples_split=4, max_features =sqrt, ccp_alpha=0.005 with the accuracy of 0.7566120218579234
INFO 06/20/2022 12:10:22 AM TRAINING: Best random forest classifier trained
INFO 06/20/2022 12:10:22 AM TRAINING: Search for best random forest classifier model ended
INFO 06/20/2022 12:10:22 AM TRAINING: Search for best xgb classifier model started
INFO 06/20/2022 12:10:22 AM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['learning_rate', 'colsample_bytree', 'max_depth', 'n_estimators', 'verbosity'])) of xgb classifier
INFO 06/20/2022 12:20:32 AM TRAINING: The optimum parameters of xgb-classifier are learning_rate=0.3, max_depth=15, colsample_bytree=0.7, n_estimators =300 with the accuracy score of 0.730327868852459
INFO 06/20/2022 12:20:33 AM TRAINING: Best xgb classifier trained
INFO 06/20/2022 12:20:33 AM TRAINING: Search for best xgb classifier model ended
INFO 06/20/2022 12:20:33 AM TRAINING: The best model is svc with accuracy of 0.696078431372549for 102 instances
INFO 06/20/2022 12:20:33 AM TRAINING: Search for best model started
INFO 06/20/2022 12:20:33 AM TRAINING: Search for best logistic regressor model started
INFO 06/20/2022 12:20:33 AM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'penalty', 'solver']))  of Logistic Regressor
INFO 06/20/2022 12:21:20 AM TRAINING: The optimum parameters of Logistic Regressor are C=10, penalty=l1,solver=saga  with the accuracy score of 0.6729842619527112
INFO 06/20/2022 12:21:21 AM TRAINING: Best Logistic  Regressor trained
INFO 06/20/2022 12:21:21 AM TRAINING: Search for best logistic regressor model ended
INFO 06/20/2022 12:21:21 AM TRAINING: Search for best svc model started
INFO 06/20/2022 12:21:21 AM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'kernel', 'degree', 'gamma'])) of SVC
INFO 06/20/2022 12:21:45 AM TRAINING: The optimum parameters of SVC are kernel=rbf, gamma=scale, C=10, degree =2 with the accuracy score of 0.7334843738345641
INFO 06/20/2022 12:21:45 AM TRAINING: Best SVC trained
INFO 06/20/2022 12:21:45 AM TRAINING: Search for best svc model ended
INFO 06/20/2022 12:21:45 AM TRAINING: Search for best random forest classifier model started
INFO 06/20/2022 12:21:45 AM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['n_estimators', 'criterion', 'min_samples_split', 'max_features', 'ccp_alpha'])) of random forest classifier 
INFO 06/20/2022 12:35:54 AM TRAINING: The optimum parameters of random forrest classifier are n_estimators=130, criterion=entropy, min_samples_split=3, max_features =log2, ccp_alpha=0.001 with the accuracy of 0.7964757216379503
INFO 06/20/2022 12:35:55 AM TRAINING: Best random forest classifier trained
INFO 06/20/2022 12:35:55 AM TRAINING: Search for best random forest classifier model ended
INFO 06/20/2022 12:35:55 AM TRAINING: Search for best xgb classifier model started
INFO 06/20/2022 12:35:55 AM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['learning_rate', 'colsample_bytree', 'max_depth', 'n_estimators', 'verbosity'])) of xgb classifier
INFO 06/20/2022 01:15:51 AM TRAINING: The optimum parameters of xgb-classifier are learning_rate=0.01, max_depth=15, colsample_bytree=0.5, n_estimators =3000 with the accuracy score of 0.795821212799284
INFO 06/20/2022 01:16:23 AM TRAINING: Best xgb classifier trained
INFO 06/20/2022 01:16:24 AM TRAINING: Search for best xgb classifier model ended
INFO 06/20/2022 01:16:24 AM TRAINING: The best model is xgb classifier with accuracy of 0.8095238095238095for 546 instances
INFO 06/20/2022 01:16:24 AM TRAINING: Search for best model started
INFO 06/20/2022 01:16:24 AM TRAINING: Search for best logistic regressor model started
INFO 06/20/2022 01:16:24 AM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'penalty', 'solver']))  of Logistic Regressor
INFO 06/20/2022 01:16:33 AM TRAINING: The optimum parameters of Logistic Regressor are C=1, penalty=l2,solver=newton-cg  with the accuracy score of 0.8538461538461538
INFO 06/20/2022 01:16:33 AM TRAINING: Best Logistic  Regressor trained
INFO 06/20/2022 01:16:33 AM TRAINING: Search for best logistic regressor model ended
INFO 06/20/2022 01:16:33 AM TRAINING: Search for best svc model started
INFO 06/20/2022 01:16:33 AM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'kernel', 'degree', 'gamma'])) of SVC
INFO 06/20/2022 01:16:35 AM TRAINING: The optimum parameters of SVC are kernel=poly, gamma=auto, C=0.3, degree =5 with the accuracy score of 0.8589743589743589
INFO 06/20/2022 01:16:35 AM TRAINING: Best SVC trained
INFO 06/20/2022 01:16:35 AM TRAINING: Search for best svc model ended
INFO 06/20/2022 01:16:35 AM TRAINING: Search for best random forest classifier model started
INFO 06/20/2022 01:16:35 AM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['n_estimators', 'criterion', 'min_samples_split', 'max_features', 'ccp_alpha'])) of random forest classifier 
INFO 06/20/2022 01:21:29 AM TRAINING: The optimum parameters of random forrest classifier are n_estimators=100, criterion=entropy, min_samples_split=2, max_features =sqrt, ccp_alpha=0.002 with the accuracy of 0.8743589743589745
INFO 06/20/2022 01:21:30 AM TRAINING: Best random forest classifier trained
INFO 06/20/2022 01:21:30 AM TRAINING: Search for best random forest classifier model ended
INFO 06/20/2022 01:21:30 AM TRAINING: Search for best xgb classifier model started
INFO 06/20/2022 01:21:30 AM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['learning_rate', 'colsample_bytree', 'max_depth', 'n_estimators', 'verbosity'])) of xgb classifier
INFO 06/20/2022 01:32:03 AM TRAINING: The optimum parameters of xgb-classifier are learning_rate=0.03, max_depth=10, colsample_bytree=0.2, n_estimators =300 with the accuracy score of 0.8717948717948717
INFO 06/20/2022 01:32:04 AM TRAINING: Best xgb classifier trained
INFO 06/20/2022 01:32:04 AM TRAINING: Search for best xgb classifier model ended
INFO 06/20/2022 01:32:04 AM TRAINING: The best model is svc with accuracy of 0.8615384615384616for 130 instances
INFO 06/20/2022 01:32:04 AM TRAINING: Search for best model started
INFO 06/20/2022 01:32:04 AM TRAINING: Search for best logistic regressor model started
INFO 06/20/2022 01:32:04 AM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'penalty', 'solver']))  of Logistic Regressor
INFO 06/20/2022 01:33:01 AM TRAINING: The optimum parameters of Logistic Regressor are C=10, penalty=l1,solver=saga  with the accuracy score of 0.6972502391690583
INFO 06/20/2022 01:33:01 AM TRAINING: Best Logistic  Regressor trained
INFO 06/20/2022 01:33:01 AM TRAINING: Search for best logistic regressor model ended
INFO 06/20/2022 01:33:01 AM TRAINING: Search for best svc model started
INFO 06/20/2022 01:33:01 AM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'kernel', 'degree', 'gamma'])) of SVC
INFO 06/20/2022 01:33:17 AM TRAINING: The optimum parameters of SVC are kernel=rbf, gamma=auto, C=10, degree =2 with the accuracy score of 0.7742462757960913
INFO 06/20/2022 01:33:17 AM TRAINING: Best SVC trained
INFO 06/20/2022 01:33:17 AM TRAINING: Search for best svc model ended
INFO 06/20/2022 01:33:17 AM TRAINING: Search for best random forest classifier model started
INFO 06/20/2022 01:33:17 AM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['n_estimators', 'criterion', 'min_samples_split', 'max_features', 'ccp_alpha'])) of random forest classifier 
INFO 06/20/2022 01:45:15 AM TRAINING: The optimum parameters of random forrest classifier are n_estimators=130, criterion=entropy, min_samples_split=2, max_features =log2, ccp_alpha=0.001 with the accuracy of 0.8371627716277162
INFO 06/20/2022 01:45:16 AM TRAINING: Best random forest classifier trained
INFO 06/20/2022 01:45:16 AM TRAINING: Search for best random forest classifier model ended
INFO 06/20/2022 01:45:16 AM TRAINING: Search for best xgb classifier model started
INFO 06/20/2022 01:45:16 AM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['learning_rate', 'colsample_bytree', 'max_depth', 'n_estimators', 'verbosity'])) of xgb classifier
INFO 06/20/2022 02:18:16 AM TRAINING: The optimum parameters of xgb-classifier are learning_rate=0.03, max_depth=20, colsample_bytree=0.7, n_estimators =1000 with the accuracy score of 0.8201202678693453
INFO 06/20/2022 02:18:27 AM TRAINING: Best xgb classifier trained
INFO 06/20/2022 02:18:27 AM TRAINING: Search for best xgb classifier model ended
INFO 06/20/2022 02:18:27 AM TRAINING: The best model is random forest classifier with accuracy of 0.8669623059866962for 451 instances
INFO 06/20/2022 02:18:27 AM TRAINING: Search for best model started
INFO 06/20/2022 02:18:27 AM TRAINING: Search for best logistic regressor model started
INFO 06/20/2022 02:18:27 AM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'penalty', 'solver']))  of Logistic Regressor
INFO 06/20/2022 02:18:38 AM TRAINING: The optimum parameters of Logistic Regressor are C=10, penalty=l2,solver=newton-cg  with the accuracy score of 0.8065727699530516
INFO 06/20/2022 02:18:38 AM TRAINING: Best Logistic  Regressor trained
INFO 06/20/2022 02:18:38 AM TRAINING: Search for best logistic regressor model ended
INFO 06/20/2022 02:18:38 AM TRAINING: Search for best svc model started
INFO 06/20/2022 02:18:38 AM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'kernel', 'degree', 'gamma'])) of SVC
INFO 06/20/2022 02:18:40 AM TRAINING: The optimum parameters of SVC are kernel=poly, gamma=auto, C=10, degree =5 with the accuracy score of 0.8429968701095463
INFO 06/20/2022 02:18:40 AM TRAINING: Best SVC trained
INFO 06/20/2022 02:18:40 AM TRAINING: Search for best svc model ended
INFO 06/20/2022 02:18:40 AM TRAINING: Search for best random forest classifier model started
INFO 06/20/2022 02:18:40 AM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['n_estimators', 'criterion', 'min_samples_split', 'max_features', 'ccp_alpha'])) of random forest classifier 
INFO 06/20/2022 02:23:45 AM TRAINING: The optimum parameters of random forrest classifier are n_estimators=300, criterion=gini, min_samples_split=3, max_features =log2, ccp_alpha=0.001 with the accuracy of 0.8430751173708921
INFO 06/20/2022 02:23:46 AM TRAINING: Best random forest classifier trained
INFO 06/20/2022 02:23:46 AM TRAINING: Search for best random forest classifier model ended
INFO 06/20/2022 02:23:46 AM TRAINING: Search for best xgb classifier model started
INFO 06/20/2022 02:23:46 AM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['learning_rate', 'colsample_bytree', 'max_depth', 'n_estimators', 'verbosity'])) of xgb classifier
INFO 06/20/2022 02:33:45 AM TRAINING: The optimum parameters of xgb-classifier are learning_rate=0.3, max_depth=10, colsample_bytree=0.3, n_estimators =3000 with the accuracy score of 0.84037558685446
INFO 06/20/2022 02:33:52 AM TRAINING: Best xgb classifier trained
INFO 06/20/2022 02:33:52 AM TRAINING: Search for best xgb classifier model ended
INFO 06/20/2022 02:33:52 AM TRAINING: The best model is svc with accuracy of 0.9159663865546218for 119 instances
INFO 06/20/2022 02:33:52 AM TRAINING: Search for best model started
INFO 06/20/2022 02:33:52 AM TRAINING: Search for best logistic regressor model started
INFO 06/20/2022 02:33:52 AM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'penalty', 'solver']))  of Logistic Regressor
INFO 06/20/2022 02:34:10 AM TRAINING: The optimum parameters of Logistic Regressor are C=3, penalty=l1,solver=saga  with the accuracy score of 0.9107262302914478
INFO 06/20/2022 02:34:10 AM TRAINING: Best Logistic  Regressor trained
INFO 06/20/2022 02:34:10 AM TRAINING: Search for best logistic regressor model ended
INFO 06/20/2022 02:34:10 AM TRAINING: Search for best svc model started
INFO 06/20/2022 02:34:10 AM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'kernel', 'degree', 'gamma'])) of SVC
INFO 06/20/2022 02:34:13 AM TRAINING: The optimum parameters of SVC are kernel=linear, gamma=scale, C=3, degree =2 with the accuracy score of 0.9019827998088867
INFO 06/20/2022 02:34:13 AM TRAINING: Best SVC trained
INFO 06/20/2022 02:34:13 AM TRAINING: Search for best svc model ended
INFO 06/20/2022 02:34:13 AM TRAINING: Search for best random forest classifier model started
INFO 06/20/2022 02:34:13 AM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['n_estimators', 'criterion', 'min_samples_split', 'max_features', 'ccp_alpha'])) of random forest classifier 
INFO 06/20/2022 02:39:47 AM TRAINING: The optimum parameters of random forrest classifier are n_estimators=150, criterion=entropy, min_samples_split=3, max_features =sqrt, ccp_alpha=0.004 with the accuracy of 0.8846392737697085
INFO 06/20/2022 02:39:47 AM TRAINING: Best random forest classifier trained
INFO 06/20/2022 02:39:47 AM TRAINING: Search for best random forest classifier model ended
INFO 06/20/2022 02:39:48 AM TRAINING: Search for best xgb classifier model started
INFO 06/20/2022 02:39:48 AM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['learning_rate', 'colsample_bytree', 'max_depth', 'n_estimators', 'verbosity'])) of xgb classifier
INFO 06/20/2022 02:51:13 AM TRAINING: The optimum parameters of xgb-classifier are learning_rate=0.1, max_depth=20, colsample_bytree=0.7, n_estimators =300 with the accuracy score of 0.895484949832776
INFO 06/20/2022 02:51:15 AM TRAINING: Best xgb classifier trained
INFO 06/20/2022 02:51:15 AM TRAINING: Search for best xgb classifier model ended
INFO 06/20/2022 02:51:15 AM TRAINING: The best model is logistic regressor with accuracy of 0.9215686274509803for 153 instances
INFO 06/20/2022 02:51:15 AM TRAINING: Search for best model started
INFO 06/20/2022 02:51:15 AM TRAINING: Search for best logistic regressor model started
INFO 06/20/2022 02:51:15 AM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'penalty', 'solver']))  of Logistic Regressor
INFO 06/20/2022 02:51:41 AM TRAINING: The optimum parameters of Logistic Regressor are C=10, penalty=l2,solver=sag  with the accuracy score of 0.904367816091954
INFO 06/20/2022 02:51:41 AM TRAINING: Best Logistic  Regressor trained
INFO 06/20/2022 02:51:41 AM TRAINING: Search for best logistic regressor model ended
INFO 06/20/2022 02:51:41 AM TRAINING: Search for best svc model started
INFO 06/20/2022 02:51:41 AM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'kernel', 'degree', 'gamma'])) of SVC
INFO 06/20/2022 02:51:49 AM TRAINING: The optimum parameters of SVC are kernel=poly, gamma=scale, C=10, degree =4 with the accuracy score of 0.9098946360153256
INFO 06/20/2022 02:51:49 AM TRAINING: Best SVC trained
INFO 06/20/2022 02:51:49 AM TRAINING: Search for best svc model ended
INFO 06/20/2022 02:51:49 AM TRAINING: Search for best random forest classifier model started
INFO 06/20/2022 02:51:49 AM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['n_estimators', 'criterion', 'min_samples_split', 'max_features', 'ccp_alpha'])) of random forest classifier 
INFO 06/20/2022 02:58:26 AM TRAINING: The optimum parameters of random forrest classifier are n_estimators=100, criterion=entropy, min_samples_split=4, max_features =sqrt, ccp_alpha=0.004 with the accuracy of 0.9390229885057471
INFO 06/20/2022 02:58:26 AM TRAINING: Best random forest classifier trained
INFO 06/20/2022 02:58:26 AM TRAINING: Search for best random forest classifier model ended
INFO 06/20/2022 02:58:26 AM TRAINING: Search for best xgb classifier model started
INFO 06/20/2022 02:58:26 AM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['learning_rate', 'colsample_bytree', 'max_depth', 'n_estimators', 'verbosity'])) of xgb classifier
INFO 06/20/2022 03:10:46 AM TRAINING: The optimum parameters of xgb-classifier are learning_rate=0.03, max_depth=10, colsample_bytree=0.4, n_estimators =1000 with the accuracy score of 0.9459291187739464
INFO 06/20/2022 03:10:50 AM TRAINING: Best xgb classifier trained
INFO 06/20/2022 03:10:50 AM TRAINING: Search for best xgb classifier model ended
INFO 06/20/2022 03:10:50 AM TRAINING: The best model is xgb classifier with accuracy of 0.950207468879668for 241 instances
INFO 06/20/2022 03:10:50 AM TRAINING: Search for best model started
INFO 06/20/2022 03:10:50 AM TRAINING: Search for best logistic regressor model started
INFO 06/20/2022 03:10:50 AM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'penalty', 'solver']))  of Logistic Regressor
INFO 06/20/2022 03:11:07 AM TRAINING: The optimum parameters of Logistic Regressor are C=1, penalty=l1,solver=saga  with the accuracy score of 0.5646749421418051
INFO 06/20/2022 03:11:07 AM TRAINING: Best Logistic  Regressor trained
INFO 06/20/2022 03:11:07 AM TRAINING: Search for best logistic regressor model ended
INFO 06/20/2022 03:11:07 AM TRAINING: Search for best svc model started
INFO 06/20/2022 03:11:07 AM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'kernel', 'degree', 'gamma'])) of SVC
INFO 06/20/2022 03:11:11 AM TRAINING: The optimum parameters of SVC are kernel=poly, gamma=auto, C=10, degree =5 with the accuracy score of 0.7103934357248054
INFO 06/20/2022 03:11:11 AM TRAINING: Best SVC trained
INFO 06/20/2022 03:11:11 AM TRAINING: Search for best svc model ended
INFO 06/20/2022 03:11:11 AM TRAINING: Search for best random forest classifier model started
INFO 06/20/2022 03:11:11 AM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['n_estimators', 'criterion', 'min_samples_split', 'max_features', 'ccp_alpha'])) of random forest classifier 
INFO 06/20/2022 03:17:02 AM TRAINING: The optimum parameters of random forrest classifier are n_estimators=150, criterion=entropy, min_samples_split=4, max_features =sqrt, ccp_alpha=0.002 with the accuracy of 0.7699137386913529
INFO 06/20/2022 03:17:02 AM TRAINING: Best random forest classifier trained
INFO 06/20/2022 03:17:02 AM TRAINING: Search for best random forest classifier model ended
INFO 06/20/2022 03:17:02 AM TRAINING: Search for best xgb classifier model started
INFO 06/20/2022 03:17:02 AM TRAINING: Using RandomSearchCV to obtain the optimum parameters(dict_keys(['learning_rate', 'colsample_bytree', 'max_depth', 'n_estimators', 'verbosity'])) of xgb classifier
INFO 06/20/2022 03:28:18 AM TRAINING: The optimum parameters of xgb-classifier are learning_rate=0.1, max_depth=20, colsample_bytree=0.5, n_estimators =300 with the accuracy score of 0.7555228276877761
INFO 06/20/2022 03:28:19 AM TRAINING: Best xgb classifier trained
INFO 06/20/2022 03:28:19 AM TRAINING: Search for best xgb classifier model ended
INFO 06/20/2022 03:28:19 AM TRAINING: The best model is random forest classifier with accuracy of 0.803680981595092for 163 instances
INFO 06/28/2022 09:05:33 PM TRAINING: Search for best model started
INFO 06/28/2022 09:05:33 PM TRAINING: Search for best logistic regressor model started
INFO 06/28/2022 09:05:33 PM TRAINING: Using GridSearchCV to obtain the optimum parameters(dict_keys(['C', 'penalty', 'solver']))  of Logistic Regressor
ERROR 06/28/2022 09:05:37 PM TRAINING: There was a problem while fitting Logistic Regressor: 
ERROR 06/28/2022 09:05:37 PM TRAINING: There was a problem while obtaining best model : 
